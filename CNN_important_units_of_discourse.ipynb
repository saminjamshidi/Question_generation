{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2222,"status":"ok","timestamp":1666765082051,"user":{"displayName":"samin jamshidi","userId":"03850391065007870575"},"user_tz":360},"id":"gRG3BZJW0d2W","outputId":"a2445409-30ad-4804-bd4e-c4182fa9922b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8GtIPTYI1uwb"},"outputs":[],"source":["import pandas as pd\n","\n","testData = pd.read_csv('/content/drive/MyDrive/NLPDL/Assign1/total_test.csv')\n","trainData = pd.read_csv('/content/drive/MyDrive/NLPDL/Assign1/total_validation.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B018MWxr9jSe"},"outputs":[],"source":["testd = trainData[[\"disco_txt\",\"d_labels\"]].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sxT4JJZ4_hQy"},"outputs":[],"source":["import numpy as np\n","\n","nltst = testd.to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fqdSOjX7q3lW"},"outputs":[],"source":["vocab = set()\n","lOfU = []\n","uL = []\n","for e in nltst:\n","  labels = e[1]\n","  labelTMp = np.array(np.matrix(labels))[0]\n","  len1 = len(labelTMp)\n","\n","  for k in labelTMp:\n","    uL.append(k)\n","\n","  s = e[0].replace(\"'\", \"\").split('], [')\n","  len2 = len(s)\n","  if len2 != len1:\n","      print('Nooooot')\n","      print('>>>>>>>>>>>>>>>>>>')\n","      print(s)\n","      print(labelTMp)\n","      print('__________________')\n","\n","  newS = []\n","  for k in s:\n","    k = k.replace(\"[\", \"\").replace(\"]\", \"\")\n","    newS.append(k)\n","\n","  for k in newS:\n","    # if k != '' and k != ' ':\n","      tmp = k.split(',')\n","      lOfU.append(tmp)\n","\n","    # for j in tmp:\n","    #   vocab.add(j)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1666765099477,"user":{"displayName":"samin jamshidi","userId":"03850391065007870575"},"user_tz":360},"id":"Gop6PQduuYvY","outputId":"84f8751b-2538-4621-e613-713a74d5688f"},"outputs":[{"data":{"text/plain":["891394"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# see the number of units\n","len(lOfU)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666765099478,"user":{"displayName":"samin jamshidi","userId":"03850391065007870575"},"user_tz":360},"id":"YS9Zq2U0ueQR","outputId":"54590a43-644f-44d6-f1d8-3ea5777df009"},"outputs":[{"data":{"text/plain":["891394"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# see the number of labels\n","len(uL)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":12440,"status":"ok","timestamp":1666765111913,"user":{"displayName":"samin jamshidi","userId":"03850391065007870575"},"user_tz":360},"id":"PaQJ8_KWVQjS","outputId":"548883dd-a1b6-40b9-e16d-3eb33f9f63e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: bert_embedding in /usr/local/lib/python3.7/dist-packages (1.0.1)\n","Collecting numpy==1.14.6\n","  Using cached numpy-1.14.6-cp37-cp37m-manylinux1_x86_64.whl (13.8 MB)\n","Requirement already satisfied: gluonnlp==0.6.0 in /usr/local/lib/python3.7/dist-packages (from bert_embedding) (0.6.0)\n","Requirement already satisfied: mxnet==1.4.0 in /usr/local/lib/python3.7/dist-packages (from bert_embedding) (1.4.0)\n","Requirement already satisfied: typing==3.6.6 in /usr/local/lib/python3.7/dist-packages (from bert_embedding) (3.6.6)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.4.0->bert_embedding) (0.8.4)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.4.0->bert_embedding) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert_embedding) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert_embedding) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert_embedding) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert_embedding) (1.24.3)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yellowbrick 1.5 requires numpy>=1.16.0, but you have numpy 1.14.6 which is incompatible.\n","xarray 0.20.2 requires numpy>=1.18, but you have numpy 1.14.6 which is incompatible.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.14.6 which is incompatible.\n","transformers 4.23.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n","tifffile 2021.11.2 requires numpy>=1.15.1, but you have numpy 1.14.6 which is incompatible.\n","thinc 8.1.5 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n","tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.\n","tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.14.6 which is incompatible.\n","statsmodels 0.12.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n","spacy 3.4.2 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n","seaborn 0.11.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n","scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.14.6 which is incompatible.\n","scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.14.6 which is incompatible.\n","resampy 0.4.2 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n","pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.14.6 which is incompatible.\n","pymc 4.1.4 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n","pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n","pyarrow 6.0.1 requires numpy>=1.16.6, but you have numpy 1.14.6 which is incompatible.\n","prophet 1.1.1 requires numpy>=1.15.4, but you have numpy 1.14.6 which is incompatible.\n","plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.14.6 which is incompatible.\n","pandas 1.3.5 requires numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.14.6 which is incompatible.\n","numba 0.56.3 requires numpy<1.24,>=1.18, but you have numpy 1.14.6 which is incompatible.\n","librosa 0.8.1 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n","kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.14.6 which is incompatible.\n","jaxlib 0.3.22+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.\n","jax 0.3.23 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.\n","imgaug 0.4.0 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n","httpstan 4.6.1 requires numpy<2.0,>=1.16, but you have numpy 1.14.6 which is incompatible.\n","gym 0.25.2 requires numpy>=1.18.0, but you have numpy 1.14.6 which is incompatible.\n","cvxpy 1.2.1 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n","cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.14.6 which is incompatible.\n","cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.14.6 which is incompatible.\n","blis 0.7.9 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n","astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n","aesara 2.7.9 requires numpy>=1.17.0, but you have numpy 1.14.6 which is incompatible.\n","aeppl 0.0.33 requires numpy>=1.18.1, but you have numpy 1.14.6 which is incompatible.\u001b[0m\n","Successfully installed numpy-1.14.6\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install bert_embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UwzG5XulgoOA"},"outputs":[],"source":["import bert_embedding\n","from bert_embedding import BertEmbedding\n","bert_embedding=BertEmbedding()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":643},"executionInfo":{"elapsed":9340,"status":"ok","timestamp":1666765124249,"user":{"displayName":"samin jamshidi","userId":"03850391065007870575"},"user_tz":360},"id":"LJ71nGVva6dl","outputId":"628d80b4-0187-4144-95a2-fc1c42606ced"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting numpy>=1.17\n","  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.14.6\n","    Uninstalling numpy-1.14.6:\n","      Successfully uninstalled numpy-1.14.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","mxnet 1.4.0 requires numpy<1.15.0,>=1.8.2, but you have numpy 1.21.6 which is incompatible.\n","bert-embedding 1.0.1 requires numpy==1.14.6, but you have numpy 1.21.6 which is incompatible.\u001b[0m\n","Successfully installed numpy-1.21.6\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158,"referenced_widgets":["a0183461379d49c793cc01212a99f8f4","27f64953c9144d06970acaafb1cf12db","03f87e6fee0a42569604d82c9bc49edd","4a211152e20944dfb317895321e7ecd9","a05be7b21d484dbbb750c3a31250f8d0","c020708b22c5443eabf541662443edad","9f06fc5218294267810f65a870c5516a","fbb20f53637a42db862b7987c59c84e9","d512674b6b3343c186c9878c68755e9c","53984899f9754622b0518b9786d2402b","f815190b80dc401f8e7fb5b7a959b15e"]},"executionInfo":{"elapsed":4897,"status":"ok","timestamp":1666765129125,"user":{"displayName":"samin jamshidi","userId":"03850391065007870575"},"user_tz":360},"id":"-3LVRGbha33F","outputId":"73b339f1-11a4-4cb4-f0f9-c5bb5a3038f0"},"outputs":[{"name":"stderr","output_type":"stream","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"name":"stdout","output_type":"stream","text":["Moving 0 files to the new cache system\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0183461379d49c793cc01212a99f8f4","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from transformers import BertModel, BertTokenizer\n","model_name = 'bert-base-uncased'\n","\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","# load\n","model = BertModel.from_pretrained(model_name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3924,"status":"ok","timestamp":1666765133026,"user":{"displayName":"samin jamshidi","userId":"03850391065007870575"},"user_tz":360},"id":"u4-tO4pBbWhi","outputId":"e4877df4-091c-4450-c1f2-ad600dc90fd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.1+cu113)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n"]}],"source":["!pip install torchvision "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1oyR7JJbVHk"},"outputs":[],"source":["import torch\n","import torchvision\n","# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# torch.cuda.set_device(0) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"u9w2LCBBcGB6"},"outputs":[],"source":["totallist=[]\n","\n","count = 0\n","for k in lOfU:\n","  # if len(k) == 0:\n","  #   print('heeeeey')\n","  #   print(k)\n","  input_ids = tokenizer.encode(k, add_special_tokens=True)\n","  input_ids = torch.tensor([input_ids])\n","  with torch.no_grad():\n","    last_hidden_states = model(input_ids)[0] # Models outputs are now tuples\n","    # last_hidden_states = last_hidden_states.mean(1)\n","    # print(np.squeeze(last_hidden_states), np.squeeze(last_hidden_states).shape)\n","  totallist.append(np.squeeze(last_hidden_states))\n","  count += 1\n","  if count == 1000:\n","    break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GM6v8Zj_jQGY","outputId":"61c43ac1-f611-4a49-a25a-e79a83485b7f"},"outputs":[{"data":{"text/plain":["44"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["max = 0\n","for e in totallist:\n","  if e.shape[0] > max:\n","    max = e.shape[0]\n","max"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"P5wyg6M9jQIt","outputId":"d86131f0-a9c3-45ce-95f3-d66ffa2049f9"},"outputs":[{"data":{"text/plain":["3"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["min = 100\n","for e in totallist:\n","  if e.shape[0] < min:\n","    min = e.shape[0]\n","min"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dwKZcHxlmSwZ","outputId":"f8a7bdaf-9fce-4096-96c4-a602390da66f"},"outputs":[{"data":{"text/plain":["10.385"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["mean = 0\n","for e in totallist:\n","  mean += e.shape[0]\n","mean/len(totallist)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aNLxwiS5mgY8","outputId":"3dcce909-457f-4d46-a7ad-a7ddd094cf70"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  # This is added back by InteractiveShellApp.init_path()\n"]}],"source":["pad_idx = 0\n","x_padded = list()\n","\n","listOfEmbd = totallist.copy()  \n","\n","for i in range(len(listOfEmbd)):\n","  while listOfEmbd[i].shape[0] < 44:\n","      newrow = np.zeros(len(totallist[0][0]))\n","      listOfEmbd[i] = np.vstack([listOfEmbd[i], newrow])\n","    \n","padded = np.array(listOfEmbd)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SSTjxO4hR156","outputId":"da4d5064-331b-4bd5-8279-d2e0e5e56332"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  \n"]}],"source":["import numpy\n","listOfEmbd = numpy.array(listOfEmbd)\n","\n","listOfEmbd = np.stack( listOfEmbd, axis=0 )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZZorfnYA5T24","outputId":"8b3c8307-72b3-42aa-cf3b-87211c5eaaca"},"outputs":[{"data":{"text/plain":["(44000, 768)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["embdVocab = np.concatenate( listOfEmbd, axis=0)\n","embdVocab.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KZdmlootY22R","outputId":"cc59e4ff-9b04-4796-d504-4497349c8774"},"outputs":[{"data":{"text/plain":["(1000, 44, 768)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["listOfEmbd.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7BsCruSVu1g0"},"outputs":[],"source":["from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n","\n","# prepare tensor data sets\n","def prepare_dataset(padded_tokens, target):\n","    # prepare target into np array\n","    target = np.array(target).reshape(-1, 1)\n","    # create tensor data sets\n","    tensor_df = TensorDataset(torch.from_numpy(padded_tokens), torch.from_numpy(target))\n","    # 80% of df\n","    train_size = int(0.8 * len(tensor_df))\n","    # 20% of df\n","    val_size = len(tensor_df) - train_size\n","    # 50% of validation\n","    test_size = int(val_size - 0.5*val_size)\n","    # divide the dataset by randomly selecting samples\n","    train_dataset, val_dataset = random_split(tensor_df, [train_size, val_size])\n","    # divide validation by randomly selecting samples\n","    # print(train_size, val_size, test_size)\n","    val_dataset, test_dataset = random_split(val_dataset, [test_size, test_size])\n","\n","    return train_dataset, val_dataset, test_dataset\n","\n","# create tenor data sets\n","train_dataset, val_dataset, test_dataset = prepare_dataset(listOfEmbd, uL[:1000])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"T909oz0rdXgi"},"outputs":[],"source":["# helper function to count target distribution inside tensor data sets\n","def target_count(tensor_dataset):\n","    # set empty count containers\n","    count0 = 0\n","    count1 = 0\n","    # set total container to turn into torch tensor\n","    total = []\n","    # for every item in the tensor data set\n","    for i in tensor_dataset:\n","        # if the target is equal to 0\n","        if i[1].item() == 0:\n","            count0 += 1\n","        # if the target is equal to 1\n","        elif i[1].item() == 1:\n","            count1 += 1\n","            \n","    total.append(count0)\n","    total.append(count1)\n","    return torch.tensor(total)\n","\n","\n","# prepare weighted sampling for imbalanced classification\n","def create_sampler(target_tensor, tensor_dataset):\n","    # generate class distributions [x, y]\n","    class_sample_count = target_count(tensor_dataset)\n","    # weight\n","    weight = 1. / class_sample_count.float()\n","    # produce weights for each observation in the data set\n","    samples_weight = torch.tensor([weight[t[1]] for t in tensor_dataset])\n","    # prepare sampler\n","    sampler = torch.utils.data.WeightedRandomSampler(weights=samples_weight,\n","                                                     num_samples=len(samples_weight),\n","                                                     replacement=True)\n","    return sampler\n","\n","\n","# create samplers for just training\n","train_sampler = create_sampler(target_count(train_dataset), train_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1K3y303HdXjQ"},"outputs":[],"source":["# create DataLoaders with samplers\n","train_dataloader = DataLoader(train_dataset,\n","                              batch_size=80,\n","                              sampler=train_sampler,\n","                              shuffle=False)\n","\n","valid_dataloader = DataLoader(val_dataset,\n","                              batch_size=80,\n","                              shuffle=True)\n","\n","test_dataloader = DataLoader(test_dataset,\n","                              batch_size=80,\n","                              shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HQBXaFTLzZuW","outputId":"63ac4dd8-fb50-4511-8d80-29ac284aebfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["batch index 0, 0/1: 33/47\n","batch index 1, 0/1: 34/46\n","batch index 2, 0/1: 35/45\n","batch index 3, 0/1: 37/43\n","batch index 4, 0/1: 49/31\n","batch index 5, 0/1: 41/39\n","batch index 6, 0/1: 39/41\n","batch index 7, 0/1: 40/40\n","batch index 8, 0/1: 47/33\n","batch index 9, 0/1: 38/42\n"]}],"source":["# lets check class balance for each batch to see how the sampler is working\n","for i, (x, y) in enumerate(train_dataloader):\n","    if i in range(0, 10):\n","        print(\"batch index {}, 0/1: {}/{}\".format(\n","            i, (y == 0).sum(), (y == 1).sum()))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KnudMq2n1Lxg","outputId":"3e1f60a1-b17d-4b09-a642-0d1edebc18bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (3.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.7.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.8.1)\n","Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n","Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n","Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n","Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.42)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (1.2.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3.post0)\n","Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.2)\n","Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n","Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.11.0)\n","Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.2)\n","Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.4.1)\n","Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n","Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n","Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"]}],"source":["!pip install optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eRPwz_AJ01Mv"},"outputs":[],"source":["# load python\n","# library(reticulate)\n","# use_condaenv(\"my_ml\")\n","# load packages\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n","import time, datetime, re, random, string\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from collections import Counter\n","from transformers import get_linear_schedule_with_warmup\n","from itertools import repeat\n","import optuna\n","from optuna.pruners import SuccessiveHalvingPruner\n","from optuna.samplers import TPESampler\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from torch.cuda.amp import autocast, GradScaler\n","from transformers import get_linear_schedule_with_warmup, AdamW\n","\n","SEED = 15\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","torch.backends.cudnn.deterministic = True\n","torch.cuda.amp.autocast(enabled=True)\n","\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CAMXMkgmzZw3"},"outputs":[],"source":["# Build Kim Yoon CNN\n","class KimCNN(nn.Module):\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        output_channel = config.output_channel  # number of kernels\n","        num_classes = config.num_classes  # number of targets to predict\n","        vocab_size = config.vocab_size  # vocab size of corpus\n","        embedding_dim = config.embedding_dim  # GloVe embed dim size\n","        pre_embed = config.pre_embed  # GloVe coefs\n","        self.mode = config.mode  # static, or not\n","        ks = 3  # three conv nets here\n","        dropout = config.dropout  # dropout value\n","        padding = config.padding_idx  # padding indx value\n","\n","        # for single embedding, input_channel = 1\n","        input_channel = 1\n","        if config.mode == 'rand':\n","            rand_embed_init = torch.Tensor(vocab_size, embedding_dim).uniform_(-0.25, 0.25)\n","            self.embed = nn.Embedding.from_pretrained(rand_embed_init, freeze=False)\n","\n","        elif config.mode == 'static':\n","            self.static_embed = nn.Embedding.from_pretrained(pre_embed,\n","                                                             freeze=True,\n","                                                             padding_idx=padding)\n","\n","        elif config.mode == 'non-static':\n","            self.non_static_embed = nn.Embedding.from_pretrained(pre_embed,\n","                                                                 freeze=False,\n","                                                                 padding_idx=padding)\n","\n","        # input channel increases with trainable and untrainable embeddings\n","        elif config.mode == 'multichannel':\n","            self.static_embed = nn.Embedding.from_pretrained(pre_embed,\n","                                                             freeze=True,\n","                                                             padding_idx=padding)\n","            self.non_static_embed = nn.Embedding.from_pretrained(pre_embed,\n","                                                                 freeze=False,\n","                                                                 padding_idx=padding)\n","            input_channel = 2\n","\n","        else:\n","            print(\"Unsupported Mode\")\n","            raise Exception\n","\n","        # input_channel = word embeddings at a value of 1; 3 for RGB images\n","        # output_channel = number of kernels\n","        # [3, 4, 5] = window height\n","        # embedding_dim = length of embedding dim; my GloVe is 202\n","        # padding = padding to account for height of search window\n","        self.conv1 = nn.Conv2d(input_channel, output_channel, (3, embedding_dim), padding=(2, 0))\n","        self.conv2 = nn.Conv2d(input_channel, output_channel, (4, embedding_dim), padding=(3, 0))\n","        self.conv3 = nn.Conv2d(input_channel, output_channel, (5, embedding_dim), padding=(4, 0))\n","        # apply dropout\n","        self.dropout = nn.Dropout(dropout)\n","        # fully connected layer for classification\n","        # 3x conv nets * output channel\n","        self.fc1 = nn.Linear(ks * output_channel, num_classes)\n","\n","    def forward(self, x, **kwargs):\n","        if self.mode == 'rand':\n","            word_input = self.embed(x)  # (batch, sent_len, embed_dim)\n","            x = word_input.unsqueeze(1)  # (batch, channel_input, sent_len, embed_dim)\n","\n","        elif self.mode == 'static':\n","            static_input = self.static_embed(x)\n","            x = static_input.unsqueeze(1)  # (batch, channel_input, sent_len, embed_dim)\n","\n","        elif self.mode == 'non-static':\n","            non_static_input = self.non_static_embed(x)\n","            x = non_static_input.unsqueeze(1)  # (batch, channel_input, sent_len, embed_dim)\n","\n","        elif self.mode == 'multichannel':\n","            non_static_input = self.non_static_embed(x)\n","            static_input = self.static_embed(x)\n","            x = torch.stack([non_static_input, static_input], dim=1)  # (batch, channel_input=2, sent_len, embed_dim)\n","\n","        else:\n","            print(\"Unsupported Mode\")\n","            raise Exception\n","\n","        # squeeze to get size; (batch, channel_output, ~=sent_len) * ks\n","        x = [F.relu(self.conv1(x)).squeeze(3), F.relu(self.conv2(x)).squeeze(3), F.relu(self.conv3(x)).squeeze(3)]\n","        # max-over-time pooling; # (batch, channel_output) * ks\n","        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n","        # concat results; (batch, channel_output * ks)\n","        x = torch.cat(x, 1)\n","        # add dropout\n","        x = self.dropout(x)\n","        # generate logits (batch, target_size)\n","        logit = self.fc1(x)\n","        return logit"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rWA-gURl0CSV"},"outputs":[],"source":["# time function\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    # format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rAvREV7o0CUy"},"outputs":[],"source":["def train(model, dataloader, optimizer, criterion):\n","\n","    # capture time\n","    total_t0 = time.time()\n","\n","    # Perform one full pass over the training set.\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n","    print('Training...')\n","\n","    # reset total loss for epoch\n","    train_total_loss = 0\n","    total_train_f1 = 0\n","\n","    # put model into traning mode\n","    model.train()\n","\n","    # for each batch of training data...\n","    for step, batch in enumerate(dataloader):\n","\n","        # progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","\n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(dataloader)))\n","\n","        # Unpack this training batch from our dataloader:\n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU\n","        #\n","        # `batch` contains two pytorch tensors:\n","        #   [0]: input ids\n","        #   [1]: labels\n","        b_input_ids = batch[0].cuda()\n","        b_labels = batch[1].cuda().long()\n","\n","        # clear previously calculated gradients\n","        optimizer.zero_grad()\n","\n","        with autocast():\n","            # forward propagation (evaluate model on training batch)\n","            logits = model(b_input_ids)\n","\n","        # calculate cross entropy loss\n","        loss = criterion(logits.view(-1, 2), b_labels.view(-1))\n","\n","        # sum the training loss over all batches for average loss at end\n","        # loss is a tensor containing a single value\n","        train_total_loss += loss.item()\n","\n","        # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n","        # Backward passes under autocast are not recommended.\n","        # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n","        scaler.scale(loss).backward()\n","\n","        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n","        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n","        # otherwise, optimizer.step() is skipped.\n","        scaler.step(optimizer)\n","\n","        # Updates the scale for next iteration.\n","        scaler.update()\n","\n","        # update the learning rate\n","        scheduler.step()\n","\n","        # get preds\n","        _, predicted = torch.max(logits, 1)\n","\n","        # move logits and labels to CPU\n","        predicted = predicted.detach().cpu().numpy()\n","        y_true = b_labels.detach().cpu().numpy()\n","\n","        # calculate f1\n","        total_train_f1 += f1_score(predicted, y_true,\n","                                   average='weighted',\n","                                   labels=np.unique(predicted))\n","\n","    # calculate the average loss over all of the batches\n","    avg_train_loss = train_total_loss / len(dataloader)\n","\n","    # calculate the average f1 over all of the batches\n","    avg_train_f1 = total_train_f1 / len(dataloader)\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'Train Loss': avg_train_loss,\n","            'Train F1': avg_train_f1\n","        }\n","    )\n","\n","    # training time end\n","    training_time = format_time(time.time() - total_t0)\n","\n","    # print result summaries\n","    print(\"\")\n","    print(\"summary results\")\n","    print(\"epoch | trn loss | trn f1 | trn time \")\n","    print(f\"{epoch+1:5d} | {avg_train_loss:.5f} | {avg_train_f1:.5f} | {training_time:}\")\n","\n","    torch.cuda.empty_cache()\n","\n","    return None\n","\n","\n","def validating(model, dataloader, criterion):\n","\n","    # capture validation time\n","    total_t0 = time.time()\n","\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    # put the model in evaluation mode\n","    model.eval()\n","\n","    # track variables\n","    total_valid_accuracy = 0\n","    total_valid_loss = 0\n","    total_valid_f1 = 0\n","    total_valid_recall = 0\n","    total_valid_precision = 0\n","\n","    # evaluate data for one epoch\n","    for batch in dataloader:\n","\n","        # unpack batch from dataloader\n","        b_input_ids = batch[0].cuda()\n","        b_labels = batch[1].cuda().long()\n","\n","        # tell pytorch not to bother calculating gradients\n","        # as its only necessary for training\n","        with torch.no_grad():\n","\n","            # forward propagation (evaluate model on training batch)\n","            logits = model(b_input_ids)\n","\n","            # calculate BCEWithLogitsLoss\n","            loss = criterion(logits.view(-1, 2), b_labels.view(-1))\n","\n","            # calculate preds\n","            _, predicted = torch.max(logits, 1)\n","\n","        # accumulate validation loss\n","        total_valid_loss += loss.item()\n","\n","        # move logits and labels to CPU\n","        predicted = predicted.detach().cpu().numpy()\n","        y_true = b_labels.detach().cpu().numpy()\n","\n","        # calculate f1\n","        total_valid_f1 += f1_score(predicted, y_true,\n","                                   average='weighted',\n","                                   labels=np.unique(predicted))\n","\n","        # calculate accuracy\n","        total_valid_accuracy += accuracy_score(predicted, y_true)\n","\n","        # calculate precision\n","        total_valid_precision += precision_score(predicted, y_true,\n","                                                 average='weighted',\n","                                                 labels=np.unique(predicted))\n","\n","        # calculate recall\n","        total_valid_recall += recall_score(predicted, y_true,\n","                                                 average='weighted',\n","                                                 labels=np.unique(predicted))\n","\n","    # report final accuracy of validation run\n","    avg_accuracy = total_valid_accuracy / len(dataloader)\n","\n","    # report final f1 of validation run\n","    global avg_val_f1\n","    avg_val_f1 = total_valid_f1 / len(dataloader)\n","\n","    # report final f1 of validation run\n","    avg_precision = total_valid_precision / len(dataloader)\n","\n","    # report final f1 of validation run\n","    avg_recall = total_valid_recall / len(dataloader)\n","\n","    # calculate the average loss over all of the batches.\n","    avg_val_loss = total_valid_loss / len(dataloader)\n","\n","    # Record all statistics from this epoch.\n","    valid_stats.append(\n","        {\n","            'Val Loss': avg_val_loss,\n","            'Val Accur.': avg_accuracy,\n","            'Val precision': avg_precision,\n","            'Val recall': avg_recall,\n","            'Val F1': avg_val_f1\n","        }\n","    )\n","\n","    # capture end validation time\n","    training_time = format_time(time.time() - total_t0)\n","\n","    # print result summaries\n","    print(\"\")\n","    print(\"summary results\")\n","    print(\"epoch | val loss | val f1 | val time\")\n","    print(f\"{epoch+1:5d} | {avg_val_loss:.5f} | {avg_val_f1:.5f} | {training_time:}\")\n","\n","    return None\n","\n","\n","def testing(model, dataloader, criterion):\n","\n","    print(\"\")\n","    print(\"Running Testing...\")\n","\n","    # put the model in evaluation mode\n","    model.eval()\n","\n","    # track variables\n","    total_test_accuracy = 0\n","    total_test_loss = 0\n","    total_test_f1 = 0\n","    total_test_recall = 0\n","    total_test_precision = 0\n","\n","    # evaluate data for one epoch\n","    for step, batch in enumerate(dataloader):\n","        # progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","\n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(dataloader)))\n","\n","        # unpack batch from dataloader\n","        b_input_ids = batch[0].cuda()\n","        b_labels = batch[1].cuda().long()\n","\n","        # tell pytorch not to bother calculating gradients\n","        # only necessary for training\n","        with torch.no_grad():\n","\n","            # forward propagation (evaluate model on training batch)\n","            logits = model(b_input_ids)\n","\n","            # calculate cross entropy loss\n","            loss = criterion(logits.view(-1, 2), b_labels.view(-1))\n","\n","            # calculate preds\n","            _, predicted = torch.max(logits, 1)\n","\n","            # accumulate validation loss\n","            total_test_loss += loss.item()\n","\n","        # move logits and labels to CPU\n","        predicted = predicted.detach().cpu().numpy()\n","        y_true = b_labels.detach().cpu().numpy()\n","\n","        # calculate f1\n","        total_test_f1 += f1_score(predicted, y_true,\n","                                   average='weighted',\n","                                   labels=np.unique(predicted))\n","\n","        # calculate accuracy\n","        total_test_accuracy += accuracy_score(predicted, y_true)\n","\n","        # calculate precision\n","        total_test_precision += precision_score(predicted, y_true,\n","                                                 average='weighted',\n","                                                 labels=np.unique(predicted))\n","\n","        # calculate recall\n","        total_test_recall += recall_score(predicted, y_true,\n","                                                 average='weighted',\n","                                                 labels=np.unique(predicted))\n","\n","    # report final accuracy of validation run\n","    avg_accuracy = total_test_accuracy / len(dataloader)\n","\n","    # report final f1 of validation run\n","    avg_test_f1 = total_test_f1 / len(dataloader)\n","\n","    # report final f1 of validation run\n","    avg_precision = total_test_precision / len(dataloader)\n","\n","    # report final f1 of validation run\n","    avg_recall = total_test_recall / len(dataloader)\n","\n","    # calculate the average loss over all of the batches.\n","    avg_test_loss = total_test_loss / len(dataloader)\n","\n","    # Record all statistics from this epoch.\n","    test_stats.append(\n","        {\n","            'Test Loss': avg_test_loss,\n","            'Test Accur.': avg_accuracy,\n","            'Test precision': avg_precision,\n","            'Test recall': avg_recall,\n","            'Test F1': avg_test_f1\n","        }\n","    )\n","    return None"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fJpml3-30CXM"},"outputs":[],"source":["# instantiate model config -- set ex-post from optuna search\n","class config:\n","    def __init__(self):\n","        config.pre_embed = torch.from_numpy(embdVocab)  # GloVe vectors\n","        config.mode = 'static'  # dont train embedding\n","        config.num_classes = 2  # binary\n","        config.output_channel = 300  # number of kernels\n","        config.embedding_dim = 768  # GloVe embed dimension (202)\n","        config.vocab_size = len(embdVocab)+2  # vocab size of corpus plus unknown/padding\n","        config.dropout = 0.1  # dropout value\n","        config.padding_idx = 44  # padding token index\n","        return None\n","\n","# create config\n","config1 = config()\n","\n","# instantiate model - attach to GPU\n","model = KimCNN(config1).cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"L2LGrAoA0CZv","outputId":"6b7ae16d-0f38-4332-b705-537de68581ee"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["# set loss\n","criterion = nn.CrossEntropyLoss()\n","\n","# set number of epochs\n","epochs = 5\n","\n","# set optimizer\n","optimizer = AdamW(model.parameters(),\n","                  lr=0.0009978734977728082,\n","                  weight_decay=0.5\n","                )\n","\n","# set LR scheduler\n","total_steps = len(train_dataloader) * epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps=0,\n","                                            num_training_steps=total_steps)\n","                                            \n","# create gradient scaler for mixed precision\n","scaler = GradScaler()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nVBViWjA0Ccn"},"outputs":[],"source":["# create training result storage\n","training_stats = []\n","valid_stats = []\n","best_valid_loss = float('inf')\n","\n","# for each epoch\n","for epoch in range(epochs):\n","    # train\n","    train(model, train_dataloader, optimizer, criterion)\n","    # validate\n","    validating(model, valid_dataloader, criterion)\n","    # check validation loss\n","    if valid_stats[epoch]['Val Loss'] < best_valid_loss:\n","        best_valid_loss = valid_stats[epoch]['Val Loss']\n","        # save best model for use later\n","        torch.save(model.state_dict(), 'cnn-model1.pt')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyPC3PMw2VIXaDs/SdxPtaxy"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03f87e6fee0a42569604d82c9bc49edd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbb20f53637a42db862b7987c59c84e9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d512674b6b3343c186c9878c68755e9c","value":0}},"27f64953c9144d06970acaafb1cf12db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c020708b22c5443eabf541662443edad","placeholder":"","style":"IPY_MODEL_9f06fc5218294267810f65a870c5516a","value":""}},"4a211152e20944dfb317895321e7ecd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53984899f9754622b0518b9786d2402b","placeholder":"","style":"IPY_MODEL_f815190b80dc401f8e7fb5b7a959b15e","value":" 0/0 [00:00&lt;?, ?it/s]"}},"53984899f9754622b0518b9786d2402b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f06fc5218294267810f65a870c5516a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0183461379d49c793cc01212a99f8f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27f64953c9144d06970acaafb1cf12db","IPY_MODEL_03f87e6fee0a42569604d82c9bc49edd","IPY_MODEL_4a211152e20944dfb317895321e7ecd9"],"layout":"IPY_MODEL_a05be7b21d484dbbb750c3a31250f8d0"}},"a05be7b21d484dbbb750c3a31250f8d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c020708b22c5443eabf541662443edad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d512674b6b3343c186c9878c68755e9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f815190b80dc401f8e7fb5b7a959b15e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbb20f53637a42db862b7987c59c84e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}}}}},"nbformat":4,"nbformat_minor":0}